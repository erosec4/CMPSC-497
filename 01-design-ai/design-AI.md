<p><red> # 1. _Name a real-world example of an existing AI system that is problematic in that it actually enacts existing problematic social systems/practices_ </red>
Recommendation systems are an example of an AI system that can be harmful when implemented irresponsibly. The algorithm employed by the popular social media app Tik Tok is a well-known example of one such system. This algorithm seems to perfectly curate every user's "For You" page to their interests within minutes of scrolling on the app. Many users have pointed out the negative side effects of this addictive algorithm, such as shortened attention spans and dramatic increases in screen time. Of course, everyone has a personal responsibility to regulate their own screen time, but when such a powerful algorithm can get so many users addicted to an application, it raises the question: At what point are the developers of the application responsible for intentional psychological effects? The appeal of this shiny improved technology and the wide-reaching globalization of the app has blinded the general public to the long-term implications of normalizing such technology use. As Benjamin describes in *Discriminatory Design, Liberating Imagination*, we need to start "questioning breathless claimes of techno-utopianism, rethinking what counts as innovation." Benjamin was talking specifically about issues of racial justice, but the sentiment applies here too, as consideration for wellbeing is necessary to ensure that innovation is moving us towards a sustainable and healthy future and not a superficial idea of utopia. Tik Tok has been banned in many cases over privacy concerns, which also relates to the recommender engine as it collects personal data to improve personalization (in addition to content-based and collaborative filtering), but little direct action has been taken over concerns of psychological effects.

# 2. _Describe this system in terms of (your perceived high-level) goals, environment, and adaptations of the system_
![image](https://github.com/erosec4/CMPSC-497/assets/87323555/148147fc-10e8-4cfc-a3af-b1633c7347a3)


# 3. _Describe a potential reimagined system in terms of **goals**, **environment**, and **adaptations**. How does it improve upon the system described in 2?_
A better, more advanced recommendation system could be based on research about what kind of content promotes healthier brain functions for users with similar habits (a more holistic approach to healthy content consumption). The environment would be similar, just with more options for self-regulation. It could adapt to recognize harmful patterns in user activity and provide interventions.
